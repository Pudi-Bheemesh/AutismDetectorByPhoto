{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pudi-Bheemesh/AutismDetectorByPhoto/blob/main/Project_official.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrqCCvHmKO6Q"
      },
      "source": [
        "# Detection  of Autism Spectrum Disorder with image\n",
        "\n",
        "This notebook is to build an end-to-end binary-class image classification using Tensorflow 2.0 and Teensorflow Hub.\n",
        "\n",
        "## 1. Problem\n",
        "\n",
        "Identifing weather a child has ASD(Autism Spectrum Disorder)\n",
        "By  this Deep learning model we can find the symptoms of ASD and help the child with helping with hospitalisation and other methods.\n",
        "\n",
        "## 2. Data\n",
        "\n",
        "The data we use is from Kaggle's Autism_Image_Data dataset\n",
        "\n",
        "https://www.kaggle.com/datasets/cihan063/autism-image-data\n",
        "\n",
        "\n",
        "## 3. Evaluation\n",
        "\n",
        "The evaluation is a file with a prediction probabilities for a child with or without autism each test page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2u4UQ5JE8wzY"
      },
      "outputs": [],
      "source": [
        "# !unzip \"drive/MyDrive/data/archive.zip\" -d \"drive/MyDrive/data/\"\n",
        "# Use the '-d' parameter as the destination for where the files should go"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ-GJxdJLmRS"
      },
      "source": [
        "#Getting our workspace ready\n",
        "\n",
        "Let's run some import statements. And check whether or not we're using a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXhUamJGMTB4",
        "outputId": "f4d7360b-1fb8-4747-acfd-ad67afb201b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.18.0\n",
            "Hub version: 0.16.1\n",
            "GPU available (YESS!!!!)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "\n",
        "# Check for GPU\n",
        "print(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPgzIriDMVUt"
      },
      "source": [
        "a GPU is a computer chip which is faster at doing numerical computing. And since machine learning is all about finding patterns in numbers, that's what we're after.\n",
        "\n",
        "Running this for the first time in Colab will let us know there's no GPU available.\n",
        "\n",
        "This is because by default Colab runs on a computer located on Google's servers which doesn't have a GPU attached to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SZW6Ejnc0pI_"
      },
      "outputs": [],
      "source": [
        "# importing necessary libraries\n",
        "import os\n",
        "import random\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ukc9aYaE09Cn"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS5gHOGXVnuR"
      },
      "source": [
        "##Getting data ready\n",
        "Since much of machine learning is getting your data ready to be used with a machine learning model, we'll take extra care getting it setup.\n",
        "\n",
        "There are a few ways we could do this. Many of them are detailed in the Google Colab notebook on I/O (input and output).\n",
        "\n",
        "And because the data we're using is hosted on Kaggle, we could even use the Kaggle API.\n",
        "or we can upload it to your Google Drive, mount your drive in this notebook and import the file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_Ixa3VaY8pi"
      },
      "source": [
        "This means we'll be able to access files in our Google Drive right in this notebook.\n",
        "\n",
        "For this project, I've downloaded the data from Kaggle and uploaded it to my Google Drive as a .zip file under the folder \"Data\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtGBB3lmax2x"
      },
      "source": [
        "#Accessing the data\n",
        "We create file path for training and test data from the 'autism-image-data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBvhrKqWzmEr"
      },
      "source": [
        "* We get the 'Autistic' and 'Non-Autistic' images from train data, shuffle them and use as training images\n",
        "* The dataset has 2450 train images, with 1225 images for each 'Autistic' and 'Non-Autistic' category, our dataset is well balanced among the 2 classes\n",
        "* We also get the 300 test images from file path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "-UX6EbNE3BSV",
        "outputId": "1e0e5ed9-d9b8-4975-e028-92a7e161c06f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'drive/MyDrive/data/AutismDataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-1975067493.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"drive/MyDrive/data/AutismDataset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/data/AutismDataset'"
          ]
        }
      ],
      "source": [
        "data_dir = \"drive/MyDrive/data/AutismDataset\"\n",
        "for image_class in os.listdir(data_dir):\n",
        "  for image in os.listdir(os.path.join(data_dir,image_class)):\n",
        "    image_path = os.path.join(data_dir,image_class,image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsC34qfe-jGD"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(os.path.join(data_dir,\"train\",\"Autistic.18.jpg\"))\n",
        "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poEO1YLDHAbu"
      },
      "outputs": [],
      "source": [
        "data_directory = \"drive/MyDrive/data/AutismDataset/consolidated\"\n",
        "data = tf.keras.utils.image_dataset_from_directory(data_directory,image_size=(256,256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE8yTWggHoir"
      },
      "outputs": [],
      "source": [
        "data_iterator = data.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdETSYZbIaXv"
      },
      "outputs": [],
      "source": [
        "batch = data_iterator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDQFfdNxIqt_"
      },
      "outputs": [],
      "source": [
        "#images represented as numpy arrays\n",
        "batch[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_A4Xi-OIvsz"
      },
      "outputs": [],
      "source": [
        "#If 0 then autistic\n",
        "#If 1 then non autistic\n",
        "batch[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4BSw49XJV0W"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "for idx, img in enumerate(batch[0][:4]):\n",
        "    ax[idx].imshow(img.astype(int))\n",
        "    ax[idx].title.set_text(batch[1][idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIP2SSYOKOG3"
      },
      "outputs": [],
      "source": [
        "scaled = batch[0] /255\n",
        "scaled.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYrDUe_OPs95"
      },
      "source": [
        "# 2.Preprocess the data\n",
        "### Scale data\n",
        "We need to scale our data to set it up as equally sized variables. We can effectively applied our step on the data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SFXxKEfOC6m"
      },
      "outputs": [],
      "source": [
        "data = data.map(lambda x,y: (x/255,y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_8dQJ4-TzwY"
      },
      "source": [
        "Map function maps across the elements of the dataset\n",
        "this transformation applies to each element of this datasetthe transformed elements will be in the same order as the input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJDr3TZZTZpn"
      },
      "outputs": [],
      "source": [
        "data.as_numpy_iterator().next()[0].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E06SW6Z7cZWX"
      },
      "source": [
        "#### Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ux3c_7Q4b0dv"
      },
      "outputs": [],
      "source": [
        "train_size = int(len(data)*.6)\n",
        "val_size = int(len(data)*.3)\n",
        "test_size = int(len(data)*.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26ogaaYjcn8H"
      },
      "outputs": [],
      "source": [
        "train = data.take(train_size)\n",
        "val = data.skip(train_size).take(val_size)\n",
        "test = data.skip(train_size+val_size).take(test_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bALfkvxESeTM"
      },
      "outputs": [],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNIIlfg2VKHP"
      },
      "source": [
        "\n",
        "# 3.Deep Model\n",
        "#### 1.Building a deep learning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJTmxs-KUdpA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.applications.vgg16 import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xjI9eKkQ2I6"
      },
      "outputs": [],
      "source": [
        "# Calling pre-trained VGG16 model\n",
        "base_model = VGG16(include_top=False,weights='imagenet',input_shape=(256,256,3))\n",
        "# Freeze the layers in pre-trained model, we don't need to train again\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "# Let's see how many layers are in the vgg model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBdf5kGWVjYp"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRBk-NgZqg3W"
      },
      "outputs": [],
      "source": [
        "model.add(base_model)\n",
        "\n",
        "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns73ifAlk5-x"
      },
      "outputs": [],
      "source": [
        "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_alfRKcYgPw"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-_4v8leYkBz"
      },
      "outputs": [],
      "source": [
        "logdir = \"drive/MyDrive/data/logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UP-D33g8aB2F"
      },
      "outputs": [],
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "hist = model.fit(train, epochs=25, validation_data=val, callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDYh9ogQhy3r"
      },
      "source": [
        "#### Plot Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6HJF-C0b9Wc"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
        "fig.suptitle('Loss', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmcN3BSdh5Vk"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
        "fig.suptitle('Accuracy', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK8WFP6ixKR_"
      },
      "source": [
        "### 9. Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyPiePsqh9Wd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U37PZgixObD"
      },
      "outputs": [],
      "source": [
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = BinaryAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGD2nunaxRnq"
      },
      "outputs": [],
      "source": [
        "for batch in test.as_numpy_iterator():\n",
        "    X, y = batch\n",
        "    yhat = model.predict(X)\n",
        "    pre.update_state(y, yhat)\n",
        "    re.update_state(y, yhat)\n",
        "    acc.update_state(y, yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S25-6stLxWy1"
      },
      "outputs": [],
      "source": [
        "print(f\"Precision:{pre.result().numpy()},Recall:{re.result().numpy()},Accuracy:{acc.result().numpy()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMUbgxC5x3sE"
      },
      "source": [
        "### 10. Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i1twk8LxcIx"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(os.path.join(data_dir,\"test\",\"Autistic.18.jpg\"))\n",
        "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzdp5cKOyY-L"
      },
      "outputs": [],
      "source": [
        "resize = tf.image.resize(img,(256,256))\n",
        "plt.imshow(resize.numpy().astype(int))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PV_Hn5qh9ZjW"
      },
      "outputs": [],
      "source": [
        "resize.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-lHWOMg8ZE6"
      },
      "outputs": [],
      "source": [
        "np.expand_dims(resize,0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHZWjWQU8kSj"
      },
      "outputs": [],
      "source": [
        "yhat = model.predict(np.expand_dims(resize/255, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrUfBr9TJ28n"
      },
      "outputs": [],
      "source": [
        "yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkDnMPOD8mj5"
      },
      "outputs": [],
      "source": [
        "if yhat > 0.5:\n",
        "    print(f'Predicted photo is Not Autistic')\n",
        "else:\n",
        "    print(f'Predicted photo is Autistic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MzXdJJoTsDs"
      },
      "outputs": [],
      "source": [
        "data_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxrBTTO583-J"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(os.path.join(data_dir,\"test\",\"Non_Autistic.105.jpg\"))\n",
        "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snKg5-YCKlv2"
      },
      "outputs": [],
      "source": [
        "resize = tf.image.resize(img,(256,256))\n",
        "plt.imshow(resize.numpy().astype(int))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wnHYGnDKuQG"
      },
      "outputs": [],
      "source": [
        "print(resize.shape)\n",
        "print(np.expand_dims(resize,0).shape)\n",
        "\n",
        "yhat = model.predict(np.expand_dims(resize/255, 0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-U4D8w-N6oa"
      },
      "outputs": [],
      "source": [
        "print(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RZWpnnTLEL7"
      },
      "outputs": [],
      "source": [
        "if yhat > 0.5:\n",
        "    print(f'Predicted photo is Not Autistic')\n",
        "else:\n",
        "    print(f'Predicted photo is Autistic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvRix3_GNJVY"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(os.path.join(data_dir,\"train\",\"Non_Autistic.149.jpg\"))\n",
        "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5--UEM58Z60"
      },
      "outputs": [],
      "source": [
        "print(resize.shape)\n",
        "print(np.expand_dims(resize,0).shape)\n",
        "\n",
        "yhat = model.predict(np.expand_dims(resize/255, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7xKZEmT8duD"
      },
      "outputs": [],
      "source": [
        "print(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufD6vaCX8g03"
      },
      "outputs": [],
      "source": [
        "if yhat > 0.5:\n",
        "    print(f'Predicted photo is Not Autistic')\n",
        "else:\n",
        "    print(f'Predicted photo is Autistic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rpq8Vtpi8kc2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}