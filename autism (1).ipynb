{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os as os \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization \n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/content/drive/MyDrive/AutismDataset/data' \n",
    "image_exts = ['jpeg','jpg', 'bmp', 'png'] \n",
    "for image_class in os.listdir(data_dir): \n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)): \n",
    "        image_path = os.path.join(data_dir, image_class, image) \n",
    "        try: \n",
    "            img = cv2.imread(image_path) \n",
    "            tip = imghdr.what(image_path) \n",
    "            if tip not in image_exts: \n",
    "                print('Image not in ext list {}'.format(image_path)) \n",
    "                os.remove(image_path) \n",
    "        except Exception as e: \n",
    "            print('Issue with image {}'.format(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "data = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/AutismDatas\n",
    " et/data') \n",
    "data_iterator = data.as_numpy_iterator() \n",
    "batch = data_iterator.next() \n",
    "batch[0].shape \n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20)) \n",
    "for idx, img in enumerate(batch[0][:4]): \n",
    "    ax[idx].imshow(img.astype(int)) \n",
    "    ax[idx].title.set_text(batch[1][idx]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y)) \n",
    "data.as_numpy_iterator().next() \n",
    "batch[0].max() \n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_size = int(len(data)*.75)+1 \n",
    "val_size = int(len(data)*.15) \n",
    "test_size = int(len(data)*.1) \n",
    " \n",
    "train = data.take(train_size) \n",
    "val = data.skip(train_size).take(val_size) \n",
    "test = data.skip(train_size+val_size).take(test_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, \n",
    "Dropout, BatchNormalization \n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau \n",
    " \n",
    "# Create a Sequential model \n",
    "model = Sequential() \n",
    " \n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu', input_shape=(256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D()) \n",
    "model.add(BatchNormalization()) \n",
    " \n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu')) \n",
    "model.add(MaxPooling2D()) \n",
    "model.add(BatchNormalization()) \n",
    " \n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu')) \n",
    "model.add(MaxPooling2D()) \n",
    "model.add(BatchNormalization()) \n",
    " \n",
    "model.add(Flatten()) \n",
    " \n",
    "model.add(Dense(256, activation='relu')) \n",
    "model.add(Dropout(0.5))  # Adding Dropout for regularization \n",
    "model.add(BatchNormalization()) \n",
    " \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    " \n",
    "# Compile the model \n",
    "model.compile(optimizer=Adam(lr=0.001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    " \n",
    "# Load your training and validation data using train_datagen \n",
    " \n",
    "# Set up callbacks \n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, \n",
    "restore_best_weights=True) \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, \n",
    "min_lr=1e-6) \n",
    " \n",
    "# Train the model \n",
    " \n",
    "model.summary() \n",
    "logdir='logs' \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir) \n",
    " \n",
    "history = model.fit( \n",
    "    train, \n",
    "    epochs=50, \n",
    "    validation_data=val, \n",
    "    callbacks=[early_stop, reduce_lr]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() \n",
    "plt.plot(history.history['loss'], color='red', label='loss') \n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss') \n",
    "fig.suptitle('Loss', fontsize=20) \n",
    "plt.legend(loc=\"upper left\") \n",
    "plt.show() \n",
    " \n",
    "fig = plt.figure() \n",
    "plt.plot(history.history['accuracy'], color='teal', label='accuracy') \n",
    "plt.plot(history.history['val_accuracy'], color='orange', label='val_accuracy') \n",
    "fig.suptitle('Accuracy', fontsize=20) \n",
    "plt.legend(loc=\"upper left\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy \n",
    " \n",
    "pre = Precision() \n",
    "re = Recall() \n",
    "acc = BinaryAccuracy() \n",
    " \n",
    "for batch in test.as_numpy_iterator(): \n",
    "    X, y = batch \n",
    "    z = model.predict(X) \n",
    "    pre.update_state(y, z) \n",
    "    re.update_state(y, z) \n",
    "    acc.update_state(y, z) \n",
    " \n",
    "print(pre.result(), re.result(), acc.result()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model \n",
    " \n",
    "model.save(os.path.join('DL models','autism(1).h5')) \n",
    " \n",
    "new_model = load_model('autism(1).h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
